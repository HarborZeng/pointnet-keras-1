{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Reshape, Dropout\n",
    "from keras.layers import Convolution1D, MaxPooling1D, BatchNormalization\n",
    "from keras.layers import Lambda\n",
    "from keras.utils import np_utils\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_mul(A, B):\n",
    "    return tf.matmul(A, B)\n",
    "\n",
    "\n",
    "def load_h5(h5_filename):\n",
    "    f = h5py.File(h5_filename)\n",
    "    data = f['data'][:]\n",
    "    label = f['label'][:]\n",
    "    return (data, label)\n",
    "\n",
    "\n",
    "def rotate_point_cloud(batch_data):\n",
    "    \"\"\" Randomly rotate the point clouds to augument the dataset\n",
    "        rotation is per shape based along up direction\n",
    "        Input:\n",
    "          BxNx3 array, original batch of point clouds\n",
    "        Return:\n",
    "          BxNx3 array, rotated batch of point clouds\n",
    "    \"\"\"\n",
    "    rotated_data = np.zeros(batch_data.shape, dtype=np.float32)\n",
    "    for k in range(batch_data.shape[0]):\n",
    "        rotation_angle = np.random.uniform() * 2 * np.pi\n",
    "        cosval = np.cos(rotation_angle)\n",
    "        sinval = np.sin(rotation_angle)\n",
    "        rotation_matrix = np.array([[cosval, 0, sinval],\n",
    "                                    [0, 1, 0],\n",
    "                                    [-sinval, 0, cosval]])\n",
    "        shape_pc = batch_data[k, ...]\n",
    "        rotated_data[k, ...] = np.dot(shape_pc.reshape((-1, 3)), rotation_matrix)\n",
    "    return rotated_data\n",
    "\n",
    "\n",
    "def jitter_point_cloud(batch_data, sigma=0.01, clip=0.05):\n",
    "    \"\"\" Randomly jitter points. jittering is per point.\n",
    "        Input:\n",
    "          BxNx3 array, original batch of point clouds\n",
    "        Return:\n",
    "          BxNx3 array, jittered batch of point clouds\n",
    "    \"\"\"\n",
    "    B, N, C = batch_data.shape\n",
    "    assert (clip > 0)\n",
    "    jittered_data = np.clip(sigma * np.random.randn(B, N, C), -1 * clip, clip)\n",
    "    jittered_data += batch_data\n",
    "    return jittered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of points in each sample\n",
    "num_points = 2048\n",
    "\n",
    "# number of categories\n",
    "k = 40\n",
    "\n",
    "# define optimizer\n",
    "adam = optimizers.Adam(lr=0.001, decay=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------ Pointnet Architecture\n",
    "# input_Transformation_net\n",
    "input_points = Input(shape=(num_points, 3))\n",
    "x = Convolution1D(64, 1, activation='relu',\n",
    "                  input_shape=(num_points, 3))(input_points)\n",
    "x = BatchNormalization()(x)\n",
    "x = Convolution1D(128, 1, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Convolution1D(1024, 1, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling1D(pool_size=num_points)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(9, weights=[np.zeros([256, 9]), np.array([1, 0, 0, 0, 1, 0, 0, 0, 1]).astype(np.float32)])(x)\n",
    "input_T = Reshape((3, 3))(x)\n",
    "\n",
    "# forward net\n",
    "g = Lambda(mat_mul, arguments={'B': input_T})(input_points)\n",
    "g = Convolution1D(64, 1, input_shape=(num_points, 3), activation='relu')(g)\n",
    "g = BatchNormalization()(g)\n",
    "g = Convolution1D(64, 1, input_shape=(num_points, 3), activation='relu')(g)\n",
    "g = BatchNormalization()(g)\n",
    "\n",
    "# feature transform net\n",
    "f = Convolution1D(64, 1, activation='relu')(g)\n",
    "f = BatchNormalization()(f)\n",
    "f = Convolution1D(128, 1, activation='relu')(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = Convolution1D(1024, 1, activation='relu')(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = MaxPooling1D(pool_size=num_points)(f)\n",
    "f = Dense(512, activation='relu')(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = Dense(256, activation='relu')(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = Dense(64 * 64, weights=[np.zeros([256, 64 * 64]), np.eye(64).flatten().astype(np.float32)])(f)\n",
    "feature_T = Reshape((64, 64))(f)\n",
    "\n",
    "# forward net\n",
    "g = Lambda(mat_mul, arguments={'B': feature_T})(g)\n",
    "g = Convolution1D(64, 1, activation='relu')(g)\n",
    "g = BatchNormalization()(g)\n",
    "g = Convolution1D(128, 1, activation='relu')(g)\n",
    "g = BatchNormalization()(g)\n",
    "g = Convolution1D(1024, 1, activation='relu')(g)\n",
    "g = BatchNormalization()(g)\n",
    "\n",
    "# global_feature\n",
    "global_feature = MaxPooling1D(pool_size=num_points)(g)\n",
    "\n",
    "# point_net_cls\n",
    "c = Dense(512, activation='relu')(global_feature)\n",
    "c = BatchNormalization()(c)\n",
    "c = Dropout(rate=0.7)(c)\n",
    "c = Dense(256, activation='relu')(c)\n",
    "c = BatchNormalization()(c)\n",
    "c = Dropout(rate=0.7)(c)\n",
    "c = Dense(k, activation='softmax')(c)\n",
    "prediction = Flatten()(c)\n",
    "# --------------------------------------------------end of pointnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2048, 3)           0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 2048, 3)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 2048, 64)          256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 2048, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 2048, 64)          4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 2048, 64)          256       \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 2048, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 2048, 64)          4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 2048, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 2048, 128)         8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 2048, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 2048, 1024)        132096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 2048, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1, 1024)           0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1, 512)            524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 1, 512)            2048      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1, 256)            131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 1, 256)            1024      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1, 40)             10280     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 40)                0         \n",
      "=================================================================\n",
      "Total params: 823,848\n",
      "Trainable params: 819,624\n",
      "Non-trainable params: 4,224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# print the model summary\n",
    "model = Model(inputs=input_points, outputs=prediction)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ply_data_train0.h5',\n",
       " 'ply_data_train1.h5',\n",
       " 'ply_data_train2.h5',\n",
       " 'ply_data_train3.h5',\n",
       " 'ply_data_train4.h5']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load train points and labels\n",
    "train_path = \"./PrepData\"\n",
    "filenames = [d for d in os.listdir(train_path)]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_points = None\n",
    "train_labels = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in filenames:\n",
    "    cur_points, cur_labels = load_h5(os.path.join(train_path, d))\n",
    "    cur_points = cur_points.reshape(1, -1, 3)\n",
    "    cur_labels = cur_labels.reshape(1, -1)\n",
    "    if train_labels is None or train_points is None:\n",
    "        train_labels = cur_labels\n",
    "        train_points = cur_points\n",
    "    else:\n",
    "        train_labels = np.hstack((train_labels, cur_labels))\n",
    "        train_points = np.hstack((train_points, cur_points))\n",
    "train_points_r = train_points.reshape(-1, num_points, 3)\n",
    "train_labels_r = train_labels.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9840"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_points_r)\n",
    "len(train_labels_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ply_data_test0.h5', 'ply_data_test1.h5']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path = \"./PrepData_test\"\n",
    "filenames = [d for d in os.listdir(test_path)]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_points = None\n",
    "test_labels = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in filenames:\n",
    "    cur_points, cur_labels = load_h5(os.path.join(test_path, d))\n",
    "    cur_points = cur_points.reshape(1, -1, 3)\n",
    "    cur_labels = cur_labels.reshape(1, -1)\n",
    "    if test_labels is None or test_points is None:\n",
    "        test_labels = cur_labels\n",
    "        test_points = cur_points\n",
    "    else:\n",
    "        test_labels = np.hstack((test_labels, cur_labels))\n",
    "        test_points = np.hstack((test_points, cur_points))\n",
    "test_points_r = test_points.reshape(-1, num_points, 3)\n",
    "test_labels_r = test_labels.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label to categorical\n",
    "Y_train = np_utils.to_categorical(train_labels_r, k)\n",
    "Y_test = np_utils.to_categorical(test_labels_r, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotateJitterPC(keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.model.x = jitter_point_cloud(rotate_point_cloud(train_points_r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "rotate_jitter_pc = RotateJitterPC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7872 samples, validate on 1968 samples\n",
      "Epoch 1/50\n",
      "7872/7872 [==============================] - 1439s 183ms/step - loss: 2.9823 - acc: 0.3388 - val_loss: 1.5906 - val_acc: 0.5325\n",
      "Epoch 2/50\n",
      "7872/7872 [==============================] - 1389s 176ms/step - loss: 1.8817 - acc: 0.5089 - val_loss: 1.1083 - val_acc: 0.6839\n",
      "Epoch 3/50\n",
      "7872/7872 [==============================] - 1378s 175ms/step - loss: 1.5067 - acc: 0.5960 - val_loss: 0.8437 - val_acc: 0.7566\n",
      "Epoch 4/50\n",
      "7872/7872 [==============================] - 1409s 179ms/step - loss: 1.3305 - acc: 0.6292 - val_loss: 1.1433 - val_acc: 0.6697\n",
      "Epoch 5/50\n",
      "7872/7872 [==============================] - 1445s 183ms/step - loss: 1.2224 - acc: 0.6504 - val_loss: 0.8576 - val_acc: 0.7388\n",
      "Epoch 6/50\n",
      "7872/7872 [==============================] - 1378s 175ms/step - loss: 1.1336 - acc: 0.6684 - val_loss: 0.8747 - val_acc: 0.7282\n",
      "Epoch 7/50\n",
      " 352/7872 [>.............................] - ETA: 21:07 - loss: 1.2549 - acc: 0.6051"
     ]
    }
   ],
   "source": [
    "# Fit model on training data\n",
    "history = model.fit(\n",
    "    train_points_r, Y_train,\n",
    "    batch_size=32, epochs=50, \n",
    "    validation_split=0.2, \n",
    "    callbacks=[rotate_jitter_pc, early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_points_r, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
